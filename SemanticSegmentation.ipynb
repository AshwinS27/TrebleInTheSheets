{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DgWlyYejDwBF"
   },
   "source": [
    "# EECS 442 Assignment 5(3): Semantic Segmentaion\n",
    "In this part, you will design and implement your Convolutional Neural Networks to perform semantic segmentation on the Microsoft Research in Cambridge (MSRC) image understanding v2 dataset.\n",
    "\n",
    "Before we start, please put your name and UMID in following format\n",
    "\n",
    ": Firstname LASTNAME, #00000000   //   e.g.) David FOUHEY, #12345678"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E54t0DTZDzpl"
   },
   "source": [
    "**Your Answer:**   \n",
    "Andrew SCHEFFER #88550453"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oFgib63vLvfU"
   },
   "source": [
    "## Setup\n",
    "First, we will install some required packages for this notebook and download the MSRC-v2 Image dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wDEtIQjnEWN5",
    "outputId": "dc9bbc04-61c5-4b51-a1ea-3944676f170f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: colormap in /Users/drewscheffer/opt/anaconda3/lib/python3.8/site-packages (1.0.4)\r\n",
      "Requirement already satisfied: easydev in /Users/drewscheffer/opt/anaconda3/lib/python3.8/site-packages (0.12.0)\r\n",
      "Requirement already satisfied: pypng in /Users/drewscheffer/opt/anaconda3/lib/python3.8/site-packages (0.0.21)\r\n",
      "Requirement already satisfied: torchsummary in /Users/drewscheffer/opt/anaconda3/lib/python3.8/site-packages (1.5.1)\r\n",
      "Requirement already satisfied: pexpect in /Users/drewscheffer/opt/anaconda3/lib/python3.8/site-packages (from easydev) (4.8.0)\r\n",
      "Requirement already satisfied: colorlog in /Users/drewscheffer/opt/anaconda3/lib/python3.8/site-packages (from easydev) (6.6.0)\r\n",
      "Requirement already satisfied: colorama in /Users/drewscheffer/opt/anaconda3/lib/python3.8/site-packages (from easydev) (0.4.3)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/drewscheffer/opt/anaconda3/lib/python3.8/site-packages (from pexpect->easydev) (0.6.0)\r\n"
     ]
    }
   ],
   "source": [
    "# install required packages and download the dataset\n",
    "# Run the command in the terminal if it failed on local Jupyter Notebook, remove \"!\" before each line\n",
    "!pip install colormap easydev pypng torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "szOGZTMpDXFa"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import png\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from colormap.colors import Color, hex2rgb\n",
    "from sklearn.metrics import average_precision_score as ap_score\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lZiuefySEJ6J",
    "outputId": "b49d569d-811e-4691-9bab-a526c516210f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the CPU. Overall speed will be slowed down\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"Using the GPU. You are good to go!\")\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print(\"Using the CPU. Overall speed will be slowed down\")\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwWirxVjELJ2"
   },
   "source": [
    "## Dataset\n",
    "We will create a custom Dataset function for the MSRC-v2 dataset. You don't have to change anything here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASS = 5\n",
    "\n",
    "class DeepScoresDataset(Dataset):\n",
    "    def __init__(self, split, \n",
    "                 split_path=\"ds2_dense/split.json\",\n",
    "                 one_hot=False):\n",
    "        super().__init__()\n",
    "        self.one_hot = one_hot\n",
    "        img_folder = 'ds2_dense/Images'\n",
    "        mask_folder = 'ds2_dense/GroundTruth'\n",
    "        GTQ_folder = 'ds2_dense/GT_Quantize'\n",
    "        \n",
    "        self.dataset = json.load(open(split_path, 'r'))[split]\n",
    "        \n",
    "        self.group2label_idx = {'void': 0, 'lineNote': 1, 'quarterRest': 2, 'clef': 3, 'middleNote': 4}\n",
    "        \n",
    "        self.img_list = [data[0] for data in self.dataset] #These are file names\n",
    "        self.mask_list = [data[1] for data in self.dataset] #These are file names\n",
    "        GTQ_list = [data[2] for data in self.dataset] #These are file names\n",
    "        self.imgs = [np.array(Image.open(os.path.join(img_folder, img))) \n",
    "                     for img in self.img_list]\n",
    "        self.masks = [np.array(Image.open(os.path.join(mask_folder, mask))) \n",
    "                      for mask in self.mask_list]\n",
    "        self.q_masks = [np.load(os.path.join(GTQ_folder, gtq))\n",
    "                        for gtq in GTQ_list]\n",
    "            \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((848, 600))\n",
    "        ])\n",
    "\n",
    "    @staticmethod\n",
    "    def rgb2str(rgb): return f\"{rgb[0]},{rgb[1]},{rgb[2]}\"\n",
    "\n",
    "    @staticmethod\n",
    "    def str2rgb(string): return [int(v) for v in string.split(',')]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = torch.FloatTensor(self.imgs[idx]).permute(2, 0, 1)\n",
    "        qmask = torch.LongTensor(self.q_masks[idx])[None, :, :]\n",
    "        qmask = qmask.squeeze()\n",
    "        if self.one_hot:\n",
    "            H, W = qmask.shape\n",
    "            qmask = torch.nn.functional.one_hot(qmask.reshape(-1), len(self.group2label_idx)).reshape(H, W, -1)\n",
    "            qmask = qmask.permute(2, 0, 1)\n",
    "            assert torch.max(qmask) == 1\n",
    "        \n",
    "#         # Resize\n",
    "#         resize = transforms.Resize(size=(img.shape[0]/2, img.shape[1]/2))\n",
    "#         img = resize(img)\n",
    "#         qmask = resize(mask)\n",
    "\n",
    "        # Random crop\n",
    "        i, j, h, w = transforms.RandomCrop.get_params(\n",
    "            img, output_size=(256, 512))\n",
    "        img = transforms.functional.crop(img, i, j, h, w)\n",
    "        qmask = transforms.functional.crop(qmask, i, j, h, w)\n",
    "        \n",
    "        \n",
    "        return img, qmask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-fU5kNVZFIpg"
   },
   "source": [
    "## Model\n",
    "Design and implement your Convolutional NeuralNetworks to perform semantic segmentation on the MSRC-v2 dataset. \n",
    "\n",
    "As mentioned in the course, a normal semantic segmentation model should output a mask with the same size as the input that indicate the pixel-wise classification for the input.\n",
    "\n",
    "Generally, the basic elements of a convolutional semantic segmentation network include:\n",
    "1. Convolutional blocks:\n",
    "    - Typically consists of multiple convolutional layers, activation layers (like ReLU layer), BatchNorm layers, and/or Dropout layers.\n",
    "2. Down-sampling layers:\n",
    "    - Can be a simple pooling layer(Max-pooling or Average-Pooling) or convolutional layer with stride not equal to 1\n",
    "3. Up-sampling layers:\n",
    "    - Can be a simple up-sampling method like bilinear interpolation or transpose/inversed convolutional layers.\n",
    "By combining these three types of blocks, you should be able to build your own model to achieve the goal of semantic segmentation.\n",
    "\n",
    "One example of designing such model inspired by U-Net [1] is:\n",
    "1. Convolutional block with several Conv-ReLU layers with #channel $3\\to C$ (input to output)\n",
    "2. Down-sampling layer with down-sampling factor $s$ (output shape $(N, C, H/s, W/s)$)\n",
    "3. Convolutional block with several Conv-ReLU layers with #channel $C\\to 2C$\n",
    "4. Down-sampling layer with down-sampling factor $s$ (output shape $(N, 2C, H/s^2, W/s^2)$)\n",
    "5. Single convolutional layer with #channel $2C\\to 2C$\n",
    "6. Up-sampling layer with up-sampling factor $s$ (output shape $(N, 2C, H/s, W/s)$)\n",
    "7. Convolutional block with several Conv-ReLU layers with #channel $2C\\to C$\n",
    "8. Up-sampling layer with up-sampling factor $s$ (output shape $(N, C, H, W)$)\n",
    "9. Convolutional block with several Conv-ReLU layers with #channel $C\\to \\text{N_CLASS}$\n",
    "\n",
    "And the final output will have the same height and width as the input image, which is $(N, \\text{N_CLASS}, H, W)$. $\\text{N_CLASS}$ indicate the number of classes in the task, you can treat the output to be a classification task on each pixel. This is also why we will use Cross-Entropy loss as the objective function of the model.\n",
    "\n",
    "Besides the architecture mentioned above, we also encourage you to try other ways to design your own semantic segmentation network with the basic elements mentioned above.\n",
    "\n",
    "You are also allowed to use tricks like skip connection in your model, but they are not necessary for you to pass this part of the assignment.\n",
    "\n",
    "[1] O. Ronneberger, P. Fischer, and T. Brox, “U-net:  Convolutional networks for biomedical image seg-mentation,”ArXiv, vol. abs/1505.04597, 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.n_class = N_CLASS\n",
    "        ########################################################################\n",
    "        # TODO: Implement a sematic segmentation model                         #\n",
    "        ########################################################################\n",
    "        self.sampling_factor = 2\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        #First Block (Downsampling 1)\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1, stride=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, padding=1, stride=1)\n",
    "        self.maxpool1 = nn.MaxPool2d(self.sampling_factor)\n",
    "        \n",
    "        #Second Block (Downsampling 2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1, stride=1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, padding=1, stride=1)\n",
    "        self.maxpool2 = nn.MaxPool2d(self.sampling_factor)\n",
    "        \n",
    "        #Center Convolution\n",
    "        self.convMiddle = nn.Conv2d(64, 64, 3, padding=1, stride=1)\n",
    "        \n",
    "        #Third block (Upsampling 1)\n",
    "        self.upsample1 = nn.Upsample(scale_factor=self.sampling_factor, mode='nearest')\n",
    "        self.conv5 = nn.Conv2d(64, 64, 3, padding=1, stride=1)\n",
    "        self.conv6 = nn.Conv2d(64, 32, 3, padding=1, stride=1)\n",
    "        \n",
    "        #Fourth block (upsampling 2)\n",
    "        self.upsample2 = nn.Upsample(scale_factor=self.sampling_factor, mode='nearest')\n",
    "        self.conv7 = nn.Conv2d(32, 32, 3, padding=1, stride=1)\n",
    "        self.conv8 = nn.Conv2d(32, 32, 3, padding=1, stride=1)\n",
    "        \n",
    "        self.conv9 = nn.Conv2d(32, self.n_class, 3, padding=1, stride=1)\n",
    "        ########################################################################\n",
    "        #                             END OF YOUR CODE                         #\n",
    "        ########################################################################\n",
    "\n",
    "    def forward(self, x):\n",
    "        ########################################################################\n",
    "        # TODO: Implement the forward pass                                     #\n",
    "        ########################################################################\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool1(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool2(x)\n",
    "        \n",
    "        x = self.convMiddle(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.upsample1(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.upsample2(x)\n",
    "        x = self.conv7(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv8(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv9(x)\n",
    "        \n",
    "        \n",
    "        ########################################################################\n",
    "        #                             END OF YOUR CODE                         #\n",
    "        ########################################################################\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kyWQnSJ21Rxd"
   },
   "source": [
    "Ininitialize your model and look at the structure of your model, [torchsummary](https://github.com/sksq96/pytorch-summary) is a useful library to look at the computation graph of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ssxWj9dA1SOb",
    "outputId": "ddbfaf72-08be-4793-c883-c10108e05041"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your network:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 112, 112]             896\n",
      "              ReLU-2         [-1, 32, 112, 112]               0\n",
      "            Conv2d-3         [-1, 32, 112, 112]           9,248\n",
      "              ReLU-4         [-1, 32, 112, 112]               0\n",
      "         MaxPool2d-5           [-1, 32, 56, 56]               0\n",
      "            Conv2d-6           [-1, 64, 56, 56]          18,496\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,928\n",
      "              ReLU-9           [-1, 64, 56, 56]               0\n",
      "        MaxPool2d-10           [-1, 64, 28, 28]               0\n",
      "           Conv2d-11           [-1, 64, 28, 28]          36,928\n",
      "             ReLU-12           [-1, 64, 28, 28]               0\n",
      "         Upsample-13           [-1, 64, 56, 56]               0\n",
      "           Conv2d-14           [-1, 64, 56, 56]          36,928\n",
      "             ReLU-15           [-1, 64, 56, 56]               0\n",
      "           Conv2d-16           [-1, 32, 56, 56]          18,464\n",
      "             ReLU-17           [-1, 32, 56, 56]               0\n",
      "         Upsample-18         [-1, 32, 112, 112]               0\n",
      "           Conv2d-19         [-1, 32, 112, 112]           9,248\n",
      "             ReLU-20         [-1, 32, 112, 112]               0\n",
      "           Conv2d-21         [-1, 32, 112, 112]           9,248\n",
      "             ReLU-22         [-1, 32, 112, 112]               0\n",
      "           Conv2d-23          [-1, 5, 112, 112]           1,445\n",
      "================================================================\n",
      "Total params: 177,829\n",
      "Trainable params: 177,829\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.14\n",
      "Forward/backward pass size (MB): 42.21\n",
      "Params size (MB): 0.68\n",
      "Estimated Total Size (MB): 43.03\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "name = 'starter_net'\n",
    "net = Net().to(device)\n",
    "# visualizing the model\n",
    "print('Your network:')\n",
    "summary(net, (3,112,112), device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XOPAI1wYFQxc"
   },
   "source": [
    "Once you have completed the model implementation in the cell above, run the cell below to load helper functions and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "QUXCW18nFK6p"
   },
   "outputs": [],
   "source": [
    "def save_label(label, path, ):\n",
    "    '''\n",
    "    Function for ploting labels.\n",
    "    '''\n",
    "    colormap = [\n",
    "        '#0080FF',\n",
    "        '#000000',\n",
    "        '#80FF80',\n",
    "        '#FF8000',\n",
    "        '#AA8000',\n",
    "    ]\n",
    "    assert(np.max(label)<len(colormap))\n",
    "    colors = [hex2rgb(color, normalise=False) for color in colormap]\n",
    "    w = png.Writer(label.shape[1], label.shape[0], palette=colors, bitdepth=4)\n",
    "    with open(path, 'wb') as f:\n",
    "        w.write(f, label)\n",
    "\n",
    "def train(trainloader, net, criterion, optimizer, device, epoch):\n",
    "    '''\n",
    "    Function for training.\n",
    "    '''\n",
    "    start = time.time()\n",
    "    running_loss = 0.0\n",
    "    cnt = 0\n",
    "    net = net.train()\n",
    "    for images, labels in tqdm(trainloader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = net(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        cnt += 1\n",
    "    end = time.time()\n",
    "    running_loss /= cnt\n",
    "    print('\\n [epoch %d] loss: %.3f elapsed time %.3f' %\n",
    "        (epoch, running_loss, end-start))\n",
    "    return running_loss\n",
    "\n",
    "def test(testloader, net, criterion, device):\n",
    "    '''\n",
    "    Function for testing.\n",
    "    '''\n",
    "    losses = 0.\n",
    "    cnt = 0\n",
    "    with torch.no_grad():\n",
    "        net = net.eval()\n",
    "        for images, labels in tqdm(testloader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            output = net(images)\n",
    "            loss = criterion(output, labels)\n",
    "            losses += loss.item()\n",
    "            cnt += 1\n",
    "    print('\\n',losses / cnt)\n",
    "    return (losses/cnt)\n",
    "\n",
    "\n",
    "def cal_AP(testloader, net, criterion, device):\n",
    "    '''\n",
    "    Calculate Average Precision\n",
    "    '''\n",
    "    losses = 0.\n",
    "    cnt = 0\n",
    "    with torch.no_grad():\n",
    "        net = net.eval()\n",
    "        preds = [[] for _ in range(N_CLASS)]\n",
    "        heatmaps = [[] for _ in range(N_CLASS)]\n",
    "        for images, labels in tqdm(testloader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            output = net(images).cpu().numpy()\n",
    "            for c in range(N_CLASS):\n",
    "                preds[c].append(output[:, c].reshape(-1))\n",
    "                heatmaps[c].append(labels[:, c].cpu().numpy().reshape(-1))\n",
    "\n",
    "        aps = []\n",
    "        for c in range(N_CLASS):\n",
    "            preds[c] = np.concatenate(preds[c])\n",
    "            heatmaps[c] = np.concatenate(heatmaps[c])\n",
    "            if heatmaps[c].max() == 0:\n",
    "                ap = float('nan')\n",
    "            else:\n",
    "                ap = ap_score(heatmaps[c], preds[c])\n",
    "                aps.append(ap)\n",
    "            print(\"AP = {}\".format(ap))\n",
    "        print(\"Average Precision (all classes) = {}\".format(np.mean(aps)))\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_result(testloader, net, device, folder='output_train'):\n",
    "    result = []\n",
    "    cnt = 1\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    with torch.no_grad():\n",
    "        net = net.eval()\n",
    "        cnt = 0\n",
    "        for images, labels in tqdm(testloader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            output = net(images)[0].cpu().numpy()\n",
    "            c, h, w = output.shape\n",
    "            assert(c == N_CLASS)\n",
    "            y = np.argmax(output, 0).astype('uint8')\n",
    "            gt = labels.cpu().data.numpy().squeeze(0).astype('uint8')\n",
    "            save_label(y, './{}/y{}.png'.format(folder, cnt))\n",
    "            save_label(gt, './{}/gt{}.png'.format(folder, cnt))\n",
    "            plt.imsave('./{}/x{}.png'.format(folder, cnt),\n",
    "                     images[0].cpu().data.numpy().astype(np.uint8).transpose(1,2,0))\n",
    "            cnt += 1\n",
    "\n",
    "def plot_hist(trn_hist, val_hist):\n",
    "    x = np.arange(len(trn_hist))\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(x, trn_hist)\n",
    "    plt.plot(x, val_hist)\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.xticks(x)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.savefig('part3_training_hist.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dKfZ2SnWnut"
   },
   "source": [
    "Experiment with with different optimizers, parameters (such as learning rate) and number of epochs. We expect you to achieve **0.65 all classes AP** on the test set. We also encourage to try to get a higher AP by improving your model design.\n",
    "\n",
    "On normal Intel core CPU configuration, a valid model design that meets this requirement takes no longer than **10 minutes** to train. The same model take no more than **5 mintues** to finish the code below on Colab. You may use this as a reference when designing your own model. A network that is too deep/too large is not encouraged considering the size of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        \n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        inputs = nn.functional.sigmoid(inputs)       \n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
    "        \n",
    "        return 1 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Rh5n-zKMFViG",
    "outputId": "29d9bbc6-d85c-425d-f1f3-b9477e239c92",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEre\n",
      "HEre\n",
      "HEre\n",
      "HEre\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start training\n",
      "-----------------Epoch = 1-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:44<00:00,  1.77s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [epoch 1] loss: 0.222 elapsed time 44.180\n",
      "Validation loss: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.58it/s]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.028695897292345764\n",
      "-----------------Epoch = 2-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:43<00:00,  1.75s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [epoch 2] loss: 0.040 elapsed time 43.641\n",
      "Validation loss: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.58it/s]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.03512777588330209\n",
      "-----------------Epoch = 3-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:45<00:00,  1.82s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [epoch 3] loss: 0.033 elapsed time 45.513\n",
      "Validation loss: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.61it/s]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.018357111758086832\n",
      "-----------------Epoch = 4-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 1/25 [00:01<00:43,  1.81s/it]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Set up the random seed for reproducibility, you should not modify the seed used here\n",
    "torch.manual_seed(442)\n",
    "random.seed(442)\n",
    "np.random.seed(442)\n",
    "\n",
    "net = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = DiceLoss()\n",
    "\n",
    "# Define the dataset and dataloder\n",
    "print(\"HEre\")\n",
    "train_data = DeepScoresDataset(\"train\")\n",
    "print(\"HEre\")\n",
    "val_data = DeepScoresDataset(\"validation\")\n",
    "print(\"HEre\")\n",
    "test_data = DeepScoresDataset(\"test\")\n",
    "print(\"HEre\")\n",
    "\n",
    "##############################################################################\n",
    "# TODO: Modify the lines below to experiment with different batchsize        #\n",
    "##############################################################################\n",
    "train_loader = DataLoader(train_data, batch_size=2)\n",
    "val_loader = DataLoader(val_data, batch_size=2)\n",
    "##############################################################################\n",
    "#                               END OF YOUR CODE                             #\n",
    "##############################################################################\n",
    "test_loader = DataLoader(test_data, batch_size=1)\n",
    "\n",
    "# ap_loader for calculating Average Precision\n",
    "ap_data = DeepScoresDataset(\"test\", one_hot=True)\n",
    "ap_loader = DataLoader(ap_data, batch_size=1)\n",
    "\n",
    "##############################################################################\n",
    "# TODO: Choose a proper optimizer for your model and set up corresponding    #\n",
    "# parameters (such as learning rate) and number of epochs.                   #\n",
    "##############################################################################\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0#1e-5\n",
    "num_epoch = 10  # TODO: Choose an appropriate number of training epochs\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate,\n",
    "                       weight_decay=weight_decay)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.2)\n",
    "##############################################################################\n",
    "#                               END OF YOUR CODE                             #\n",
    "##############################################################################\n",
    "\n",
    "print('\\nStart training')\n",
    "trn_hist = []\n",
    "val_hist = []\n",
    "net.train()\n",
    "for epoch in range(num_epoch): #TODO: Change the number of epochs\n",
    "    print('-----------------Epoch = %d-----------------' % (epoch+1))\n",
    "    trn_loss = train(train_loader, net, criterion, optimizer, device, epoch+1)\n",
    "    print('Validation loss: ')\n",
    "    val_loss = test(val_loader, net, criterion, device)\n",
    "    trn_hist.append(trn_loss)\n",
    "    val_hist.append(val_loss)\n",
    "\n",
    "net.eval()\n",
    "plot_hist(trn_hist, val_hist)\n",
    "##########################################################################\n",
    "# TODO: Submit the \"Average Precision(all classes)\" value in the report  #\n",
    "##########################################################################\n",
    "print('\\nFinished Training, Testing on test set')\n",
    "test(test_loader, net, criterion, device)\n",
    "print('\\nGenerating Unlabeled Result')\n",
    "##############################################################################\n",
    "# You can visualize your segmentation results using get_results function     #\n",
    "# Your result will be dumped in the folder 'output_test'.                    #\n",
    "# There will be three files for each image:                                  # \n",
    "#   (1) gt<num>.png (ground truth label)                                     #\n",
    "#   (2) x<num>.png (input RGB image)                                         #\n",
    "#   (3) y<num>.png (predicted output)                                        #\n",
    "#                                                                            #\n",
    "# TODO: Find a satisfactory result by running the next cell and report       #\n",
    "#       the plot of gt<num>.png, x<num>.png and y<num>.png in the pdf        #\n",
    "# Note: Your submission doesn't have to be perfect.                          #\n",
    "##############################################################################\n",
    "result = get_result(test_loader, net, device, folder='output_test')\n",
    "\n",
    "os.makedirs('./models', exist_ok=True)\n",
    "torch.save(net.state_dict(), './models/model_skiplink_{}.pth'.format(name))\n",
    "print(\"Here\")\n",
    "cal_AP(ap_loader, net, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "XwYgDofP6bh9",
    "outputId": "407405d5-12f8-479d-9a0a-da086fc044f3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/oAAAC0CAYAAAAkXFcgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeZxN9f/A8dd75s7KjGUyKAmJCpEWyi+lopJUklDfolWb1q8ohTaFrzatqL5hlCQlJaUvUtkSQkRI9mUw+3bv5/fH59zrzp07Y2aMuWO8n4/HPLif8znnvu+593zO+ZzPcsQYg1JKKaWUUkoppSqHsFAHoJRSSimllFJKqbKjFX2llFJKKaWUUqoS0Yq+UkoppZRSSilViWhFXymllFJKKaWUqkS0oq+UUkoppZRSSlUiWtFXSimllFJKKaUqEa3oH0NEpI+IGBFpXAFiqS4iQ0WkdTHzD3Vidx3t2JRShRORC0TkYxHZKiI5IpIiIktE5DkRqRvq+EpDROaKyNwiln/olD+H+7vkCOPoIyK3F5Je6rJbRGqLyOsi8qeIZIrIXhH5VUReE5GoI4n5WFHSc04h2xgqIpcGSf9QRDYfUYCli2ez87tIKmT5XGf5gvKOTVVMfmWJ9y9VRFaIyANH+/pKRBo479nHL63Ex46IXOIci2VaB/FeZxYjX7yIDBORNSKSLiL7ReR3EXlXRBLLMqaKrLDysATrPywi3QrZbrk/u92vvPy5kOXe64Ct5R1bKGlFX5VWdWAIUOqLLqVU+RKRx4CfgFrAYOByoCfwLXA38H7oojuqngMu8Psb76T/X0D6siN8nz5AgYr+kRCReGAR0AV4BegM3AN8DVwDxJTl+1VgZXHOGQIEu7B9Drj+CLZ7JFKB60Qkzj9RRE4B2jvLlQp0I7bMugFYDLwBPBOCOEpz7FyCPRbLvQ4iIuHA98C92PNAV+A2YDJwIXBieccUQoWVh8X1MFCgog+Mw/42QyEVuCDwprqIxGJjPe7KU21dVUqp44CIdABGAq8ZYx4JWPy1iAzHXjwWtY0IIM8YU+5364+EMeYv4C/vaxG50vnvImNMXmHriUiUMSb7aMd3GN2BU4BWxpgVfumfiUgoLuwrHef3ESrfYW+43QB86Jf+L2Az8A8QXu5RqYpuuTFmg/P/2U7F5mEKqewfrbI7xMdOaVwMnAdcZ4z5wi/9S+DFsu5lcDwyxmwFQtVqvhKoDdwCDPVL7wYIMIvQ3YQICf1BH+OcrioLRORyEVkmIhkiskpErgvI5+0630JE/ufk2yEiz/oXbH7dwhoEW9/5fwNgk7NorF8Xsj4ljH2ziEwUkX+JyDqnS+qPInKaiFRxulHtE5FdIvIf/25pIhItIq84nzVNRHaKyAwROT3I+1wuIr+JSJaIbBCRO4N1NxORWBF5WUQ2ie3SvElEntKCX1USTwB7nX8LMMakG2M+9L7266Z5n4iMEJHtQDZQXaxHnOM2xylLxjitz4Hr9/F/H6fbZr5u8sUtx5y8PUVkrYhki8hqESmTllinTNgqdmjDzyKSCYxwlhkRGRqQP9/nEzt04GKgnV+ZODfgbU4QkUlih0tsF9sdP/owodV0/t0ZuMA4AuK6S2xX3iyxXfzHi0jNgDy1RGSyE8d+EflARLoW8b1cKSLLnTL6NxFpIyIuEXnR+e6Tnf1XJeB9Dlum+v0eujq/ob0issc5N1T37muKOOeISCcR+dqJxfvbeUxs6533fbz76Sm/9Yc6y4KdD+qKyEdOPNkislJEbgnI4z1fti3F9+qVCXyGrdj7+xcwAShQMRPb7XiZiBx04vtBRNoG5PHu1xucz7ffiW+SiCQUMzZ17FgCxIlIohRRdgOISDcRWegcKwdE5FMRqe+/MefYfUvsNViaiHwJ1At800KOnSoi8pKI/OUcOztF5DOxQ5CGYluSAXK9x2LA+x72OkxEzhZ7vZglIttE5GlsRe5wCi1PAYwxnoD3Ke6+etvZV6ki8rmIXCjBhzlsFZFzxTnHiD2HXu0sf1TsdXGKiHwhIrUC3sclIoPk0Plvu9hr42i/PN7v/h6x1/c7nLhniEg9v3xFlYfnichUJ1ZvjC+KSIzf+puxN6Bv9lv/Q2dZga77YodLjHFizna2+YiIiF+ew54LimkCtqLv71ZgGpAemFnssJdfxJ7HDjjf99UBefyPqdEistv5TXwlAfWlikZb9CuHU4HXgOHYC/nHgKkicrrfHV+v6djuucOBK4CnAQ/573wdzg7s3bFpzna+dNJLc2e3vRP/E0Ak8Cr2omcjsAHbrbg9tpvxX8BbznpRQBzwvBNPTeA+YKHzuXcCiMiZwExs17aezns8DVTDfm6cfC5s9+UzsV3RfgfaOnlrYvepUsck5/d9MTDNGJNTwtWfwl5E3o1tWcwCXgAGAW8CMzh03LQUkYsDL5aK6bDlmIhcDiRhj+nHsEMQXgMigHWleM9A1YCPgVHAk9hKWHHdB0zE7qN7nLSUgDwTsF1Eu2FbFYYC+zl04RvMYuffj0XkJWCBMabAxQqAs/wx4HXg38BJ2DKyuYhcaIxxO1mnAS2w3+EGbGvyG4W8f2NsT5AXgDTszY8vnT8XdrjCGU6e3cAAJ5aSlqmvAV8BvYGmzvu4sd1qD3fOaQTMcT5DFnAudt/WAgY6eS4AfsG2mr/rpAVtdRJ7w2IeUAP7O/gHe+E4QURijTHvBaxSmu/V30fAHBGpZ4zZKrbS3sTZ7sVB8p+EHcaxFajixDZfRM41xqwMyPsqtqtyL+A04EVs9+QOxYxNHRsaYo+XNCDWSStQdotIP+Bt4APgWex11FBgnoicZYzxdm1+F7gJGOZsoyO27C2SiERie6m0wh6rC7Hl6hXY42kc9obBHdihU26/dYtVZojICcAP2Mr6bdibGP8G8lXAC7EMyAPeFZFhwFxjzP5CPktx99V72N5wQ4GlwGXApELePx57vI8CtmO/o89E5E3sMX8/tkX6Vez5tYffuhOxw7VeBn7GlrvPAQ2wZbi/QU6e24FE4D9OTN7ypKjysD6w3FmWCjTD9hRphL2OBjtc42tgBYfqD3uCfWDnJs1M7LCrZ7Df69XAaGwZ/WTAKkWdC4pjAjDUOef9LCInYr+TThS8oQp2/43D9qByYffxVyLS2RjzTUDeQdh90xe7X1/E9qhpZozJLWZ85csYo3/HyB/2gsoAjf3S5gK5wGl+aYnYg+JJv7ShzroDA7Y5FnsgVw94jwYB+Yban4vvdQMn353FjN37/i6/tM1AMlDNL62/k29cwPrLgP8Vsf1w7MktFXjELz0JW/jE+qXVxV4MbvZL+5fzvu0DtvsUkAMkhvr71z/9K+0f9sLBAMODLHP5//mle4/xZYD4pdd0jp8PA7Zzi5O/a8D6fQLyXeKkX+KXVtxy7CdgDRDml9bG2d7cEuyPYOXRh07atUHyG2BoQFqBz+d8jgVB1veWq8MC0r8C/ixGvM845ZDBXqQudT5D9YB43MAzAeu2c9a7znndyXndIyDfl0V8L4380ro6+b4PWH8asMnvdbHKVL/fw38D8o1xfmcSsL+LPOdgW/VczvvsD/itGOD5IOt8SP7zwQOB+8JJ/x57MyO8jL7XzdiLd3H+P9BJfwv4qajflN82wp3Puw47LCfwOJsVkP9mJ/2y4h4v+ldx/vx+c02d770G9saiG5ju5PEeK4Fld1XgIPB+wDYbOMfkw87rps72Aq8X36ZgmRd47NyO33mgkM8wlIDy10kvbpnxgvO6vl+eKtgbxKYY+/BO7A0Rg23wWY29UXliKfeVBxgQkO/1QvZVvs8HnOWkrcMpV5z00diy11vWXOTkuzXgfbzHc6uA735eQL7HnXT/zxi0PAxYz1ue3uJ8zgS/ZZuBiYV9v36vuwTuCyd9HPYmzQnO60soxrmgiFjn4pSVwHzgHef/A7A3a8Oc72BrEdsIcz7vbOCLgO/dUPD6w3t+veNoHvdH8qddkiuH9caY9d4Xxpjd2IuRYHc3pwS8/hhboDU/euEV6RdjzEG/12udf78NyLcWONk/QUR6iMgiETmAvfhNx36Wpn7Z2gJfG2MyvAnGmB3YO53+rgT+Bn52uke5nLvLs7GthW1R6tgVtEujiNTBXkz4/qTgzM3TjXNGc7TF9qiZGJDvY+xxeHEpYyyyHBPbDfs8YKrx6zFgjFmEveAoC3nYStrRMjPg9e8UoxXKGPOsk+9ObGtFAra1eJWI1HaydcRepEwKKMMWYXsWtHfytcVexH8e8DZTC3n7P40xG/1eF1VG1/PrilnSMjXYvonC3qQqkthu9u+KyN/Yi/BcbE+G6tgbRiXVHthmjJkbkD4R2wJ1ZkB6qb5XL+f4mgj8y2kRvQnb6heU2CEu/xORfdjfbC62NbBpkOyB5/xPsRfsx9U41UpoLfZ7T8beGJpEwYlAA8vuC7AtyoFlxFZne94yog22LAl2vXg4nYCdxpgvD5uzoOKWGRcAC40xW7wrGtvLaUZx3sQYMw57PXkLtjU+DFsRXi0izfzeo7j7SrDHlb/CytN0Y8x8v9fe8vR7c6jHlTfdhW2YArtvcrCt/4H7Br94vIKVSVCMcsnpZv+yiPyFrYjnYs87gu0VVFLtsWXO5ID0idhetoFlUanPBX4+AnqIfSrNv7A3JIL2NBSRc5wu+Ls4VJ52JHh5Gnj98RP2N1Fhy1Ot6FcOyUHSsoFgYwR3FfL6pDKNqPgCu0zlFJHuPw7pGuAT4A9s95422ErAHvJ/7rrYykKgwP2QiB1vlBvw5+02q2Ma1bFsL/aOeOBJfi/2uDkP27snmB0Br2sGSzd2Urt9fstL6nDl2AnYi73AY5dC0kpjd8DFVlkL/IzZ2AuYwzLG7DTGjDfG9DXGNMS2Op+E7bIKhyq0GyhYjsVzqAyrC+w3BbsZFrYPS1JGuzg0cVxJy9Rg+waCn8d8nG6hX2JbjZ7HziJ9HrbV77DrF6ImBX/3cGhcb+BvvNTfq5+PsDcQhmBbJz8Jlkns4wW/xrZI3oGt/JyH7UJ72HO+sUN39hO6c74qG9djv/fTgSrGmFuNMYG/w8DfsLeM+J6Cx2UL8pcRUPj1YlESgG3FyBdMccuMuoXEUuzzgDFmvzFmkjGmnzHmDOA6bDk5zC8WKP6+CrzOLCyWAwFxFFWewqFjOhFbKU4LiMX7vmVSnjo+APpheyV0xP7O7i/B+oFqAsmm4MS2JSlPS/reU5z8z2AbMoPeOBWRk7HDvmoCD2KfvHAedtK+4tShvGkVtjzVMfrHn9rY8e/+r+FQwZzl/BsZsF5Fq+j2BDYYY/p4E8TOKhtYYOwgeItO4J3BfdjJnnoEyQtl12KoVLkzxuSJyHygo4hEei8unMr5UgAR6VLY6gGvvSfhOtgujzjru7DlxD4nqazLkr3YC5tgd/VrY1uCjlTgZ/XKpoKVicaYN0XkOQ61Lnv3eycKXjT6L98B1BCRiIDKfklaS4qjvMrUU7Fj8v9ljPH1MnFuBpdWMsFbc+o4/+4LsuyIGGP+FJFF2DkFphljDhSS9QZsq1M3/+9PRGoQUIlw5PtenR4DNSh9ZUxVDKtMwTmYAgWWZ97fbR/8ym4/3jHn3hsEhV0vFmUvpe8hWtwyY0chsZS6DDPGfCEiKyhYnvahePsqkUMThh5RLIXYhz2nXlTI8u1l8SZiJ/a7FjtU7TW/9BZHsNlkoKb/tYfjaJanKWInkBwILDXG/FFI1iuxc0j0MPZpAYDvcXzBFPa7W34k8R5N2qJ//AksQHti7xCucl57L5Z9BbVzAd8pYD3vHbZQPcM5Fnux4+9fFHwM0UKgs/9BKyJ1seNq/M3CduVKM8YsDfK3t4zjV6q8jcC2ir98hNtZiD3+ewak34S9eTzPeb3LyRd40Xc1peC0tC8Bukv+WdvbYMfPHU1/U7zPkU0Zl4kiUifIcApvOVaNQxea32G7R9YvpAzzXoQuxJaTgU8rKPLRiqVQ1mVqYeccb9nuX+mNwI5dDZQTZP1g5mGHIQSeJ3pjW9AKu2g8UiOw3Y/HFJEnFjv0wleJE5FLKbxLbuA5/0bstd8vpQ9THaN+xlZQGxdyTHonNF2ELUuCXS8ezmygzmFutBV2LBe3zPgFaOu0xgK+CTQPe3NPRE6QIE/EcNY/mUPlaUn2laFg+Xk0ytNo7JxWweIpTUU/WHkYhT0/BPb46hNk/eKe7+Zhy5zAfXKzE8PCYmyjNMZgy9MRReQJdv5oQsE6glfg9Uc77OSSFbY81Rb9489dzo90CXYW1Duxd+68LQFLsDMZj3TyZWNnkw7shrgLexeup4isxI6P32SMKfM7c4WYBVwnIq9gx9Seg53IL7BF43nsc6i/FZFR2M/xtBO//3idSdhZNOeIyH+w3SAjsa1FXbETWWWg1DHKGDNHRAYCL4nIWdiubJuwFw9NsBdx6RTequ3dTrKIjAYGiUg6thvxGdhjbQHO+DpjjBGRT4A7RORP7GRDV2Mn3CmtIdgLyeki8i52vPQwCnlUUhn6GBgsIk9hL0ouws5iHmgNcJ+I3IQtR1P9LghL6xagv4h84Lx3Bvb7egx7kfQm2OdZi8jLwBgRaYq9uMrCXrx2xE5w+j9jzGwRWQC858xevQFbRrZ03q80T0wIpqzL1KDnHGyl+2/gBRFxYy/YHilkG2uAq0VkFrbXw/ZCLpA/BB4Cpjnf+VbsRWlH4J6jNbzDGDMNO6lhUWZhn5f+ofObaII9pxXWQt/Myfexk/cF7ERdc8omanWscFo5/w28KfbRbd9gJ5w7CTu3ylxjTJIxZp2IJAHP+l0vdgQ6F+NtJgJ3AZNFZDi2IhyHvd581RizFnscAjwmIt8AbmPMUopfZryCvS6dLfaRcN5Z94vzlJRLgLfFPgruR+w14ynYbts1sZPglWZfPefsq1+xw4e8Nx3KpDw1xswVkcnYJ9GMxg5n8GBvcncGnjDG/FnCzQYtD0VkIfa72YHtoXE7wbumrwEucnoD7gT2GmM2B8n3Dfba4B1nX652Yr4TO0HwUWlIM8YscN63KN9jGw0/cn5zdbHXFFsI3hgeR/7rj+HAeoqYUyXkTAWYEVD/ivdH4bPuB5vleTN+s2JzaJbT5sD/sAXiTuyjOcIC1m3mbDcN+2N/lIBZNJ1812EP9FyCzKgZkNf7/oGz7k8MyHeJk+/ygPQP8ZspE3sAPo/trpSBvag9O/BzO3k7YrvVZGO7od2DnYjqt4B80U6ca528ydgT3FACZofVP/07Vv+wd6qnYCsGOdiJ2pZgT251/fI1oJBZzrGT8jyCrbznYFtB3gTiA/JVx07is9c5nt7BVvbzzWhe3HLMSevlvG829oLhemf9uSXYB8HKo3xlTED+aOwjf3ZgW3k+Ac4PLPewXRG/dvIYb0wEKbv94zhMrGdgL2x/w1Z0c504pgKtg+T/F/aGQDq2DP8D27JRzy9PLWzFLxV7ofsR9tFFBmhZ1PdS2O+ikH162DKVwst87z5r4JcW9JyDfZTXAuy5YCv2UVh3Blm/HfZCPAu/JykQMHO4k1aXQ7/dbGAlcEshMZb4e/X7fReYtTogT7Dv4EHsTY5MZ39eTsAx4Ldfuzmf74DzfSfhzHKtf8feX2G/uYA8QY9Rv+WdsdeBKc5vaAP2sctn+uWJxc6yn4wtR77k0AzjffzyBTt2qmJnsfdOjuktr7yz5odjzxe7sZVV47dusa7DsI9q+9E5lrdhb3YNO9xxh2199d6A2I0tS/Zgy+1Ly3Bfec9z1wbsqwLnGILMfh/se8Ze9z6EvQGShb3xsALbYl2tqO+e4E+7Kaw8bICtnKc6+2gMwc/bpzvfQYaz7EMnfWjg94Cd/2CM81vIAf7EXkNIkBgPey4o5LudSxFPKCnsO8D2XFnr7IfV2EaPD8n/NAnvfr0PezNoj/O5ZwINQ10uFPXnfWyNquScu55DgAhjx+Uet0SkKrawnmmMuSPU8SilVKiJfY5zH6CmKThpkjrGiMgl2ApKR2PM9yEOR6njitMb4GVs5XTL4fKrik1EGmBvrt5l7FMbjhnadV9VeiLyBna81XbgROwd0RrYFjqllDquiEgf7Pj+1diusVdiZ1keqZV8pZQqPqfrenNsz1EPdmjX48AUreSrUNOKvjoeRGPvrNbGdhlajO0atDKkUSmlVGikY8d5n4qdt2QT8CS2u61SSqniS8UOKxqIfTTmNuyj6YaEMiilAO26r5RSSimllFJKVSb6eD2llFJKKaWUUqoS0Yq+UkoppZRSSilViRxujP5h+/UPGDCA8ePHs3HjRqpVq1ZGYSml1GFJqAMoLzLs8GWxUkqFghlyfJTFWg4rpSqqwsphbdFXSimllFJKKaUqEa3oK6WUUkoppZRSlYhW9JVSSimllFJKqUpEK/pKKaWUUkoppVQlohV9pZRSSimllFKqEtGKvlJKKaWUUkopVYloRV8ppZRSSimllKpEtKKvlFJKKaWUUkpVIlrRV0oppZRSSimlKhGt6CullFJKKaWUUpWIVvSVUkoppZRSSqlKpEJW9N1uN3/99Rfp6emhDqVE1q9fzz///IMxJtShKKVUmTidP0IdglJKKaWUKqEKV9HPzc1l4sSJdO3alSFDhpCWlhbqkIrt+eefZ/z48Xg8nlCHopRSR0TwcCNT+IarmMjNRJId6pCUUkoppVQxuUIdgD+3281nn33Go48+SnJyMn/99Rd16tThoYceIiIiItThHVZqairp6enaoq+UOqYJHroxjfHcQRxp1GIP07mOz7gBU/HuDyullFJKqQAV5orNGMOSJUt4/PHHSU5OBiA7O5sRI0awbNkyrTwrpVQ5uYHP+IC+xGF7VFUhg/Hcwcn8E+LIlFJKKaVUcVSYin5ycjLDhg1j27Zt+dL37NnD6NGjycjICFFkSil1/KjGAR7kDV8l3yuOVAYwIkRRKaWUUkqpkqgQFX1jDDNmzOCHH37Ilx4eHk5YWBizZ8/WVn2llDrqDJfyA+35scASAa5jOs35vfzDUkoppZRSJVIhKvrp6emMHTuWnJwcwFbw27dvz4svvsiQIUOIiYnh008/DXGUSilVuYXj5hme9b12E8YmGjCEoQzjGSLJ4Tb+C+hNV6WUUkqpiizkk/EZY1i8eDFr1qwBICoqikceeYRHHnmEWrVq4Xa7iYiIYMKECSQnJ5OQkBDiiJVSqnLqycc0YzVgK/nP8gxvcy97SAQMG2nE44zi34wMbaBKKaWUUqpIIW/R93g8/PTTTxw8eJDw8HBuv/12nnzySRITExERwsPDadWqFcnJySxfvjzU4SqlVKVVhXQiyCObSJ7jaYYzyKnkAwgHqUYjNnId00Map1JKKaWUKlrIK/q5ubksXboUYwxNmzblqaeeomrVqr7lIkJUVBQZGRmsXr1an1GvlFJHQTSZdGcqAOs5jRd4ilwiC+SrQgZ12Fne4SmllFJKqRIIeUU/Ly+PDRs2ICL06dOHunXrIiK+5cYYDhw4QEZGBuvXr8ftdocwWqWUqpwiyeEcfgXgeQaTF/qRXUoppZRSqpRCXtF3u93s2bOHxMRELrnkknyVfLAV/eXLl+N2u9mxY4dW9JVS6ijaSwJbqI+dZ/8QwcOZ2LlUTmctLnJDEJ1SSimllCqOMmmy8Xg87Nq1q1TPuj948CA5OTnUq1ePmJgYdu7M3yU0JyeHb7/9FoD9+/ezY8cOoqOjyyLsMpeVlUV6ejo7d+4kPDw81OEoVanVrVs31CFUSr/Tgl+4sEB6OG7uZBwAt/IRQxjGQaqXd3hKKaWUUqoYyqSin5aWxq233lqqyq3b7SYjI4N//vmHu+++u0CLfkpKCmvXrgVg+fLl9O7dm7CwkHdECGrt2rWsWLGC5cuXF/gc6ugzxpCRkVGiXh8ul4vY2NijGJU6Wn766adQh3BcuZQfSGAfAF/RhUxiQhyRUkoppZQqTJlU9OPi4vjkk0+Ii4sr8boZGRl06dKFxMREPv7443zLMjMzuf/++1m1ahUA3bt357nnnsPlqphjR2+99VYaNmzIM888oy36IbBv3z569erFihUrir1Ox44dGTduXL4JIJVS+cWQwZ2MoxopAPzMheQQFeKolFJKKaVUYcqkxiwiVK9enWrVqpV43SpVqnD66aezc+dO4uPjfZV4YwyLFy/mhx9+ACAsLIwWLVpQq1atCttaHhkZSXR0NDVq1KiwNyMqM7fbXeL9HhERQY0aNUp1k0qpyiQPFxtpFHTZ2fxGV74s54iUUkoppVRphbwPfEREBK1atSItLY2UlBRf+vbt2xk+fDipqakAVKtWjebNm1fYSr5SSh3LMqjCWO4qkN6Y9UymF1HkAJBDBKnojTGllFJKqYos5BV9EeGMM84gPT2d7du3Y4whJyeH1157jR9//NGX75RTTqF169YhjFQdC8LDw3G5XMX+0yEWSh3iJpwGbOZMVgMQhpvb+C8n848vz2qaMZleoQpRKaWUUkoVQ8j7l4sITZo0ITc3l7///pszzzyTiRMn8t5772GM8eW78cYbtXu1KlJcXByDBw9m7969xV7npJNOqrBPcVCqvE2mF48ymqasYy2nM4whDGBEvgftPcszeEJ/j1gppZRSShUh5BV9gAYNGhAfH8/y5cvxeDw8/fTTHDx40Le8SZMmdOvWLYQRqmNBdHQ0V111VajDUOqYlUEsec5poQGb6cc7RJLrW76f6mylHqBDqJRSSimlKrIKUdGPjo6mZcuWJCUl8fbbb7N9+3bfMpfLxd13302TJk10fL5SSh1lKcTTn9dJYB8nOI/TA3ATxj28y1LOC2F0SimllFKqOMq0ou/f1b6k65100kmsWbMmX7qI0KlTJ/r27YuIlHr7oXAsxarUsUhv/B0dL/AU39A5X5rBPlLvey4PTVBKKaWUUqpEyqSin5OTw9SpU4mNjS3V+jt27OC///1vgfTY2FjOO+88Zs2adUxc1G/dupWcnBw+/vhjneRNqaOsVy+dEK6sNWAzzzO4QPo8LuYmPmE/NUMQlVJKKaWUKqkyqejn5eXx66+/EhkZWaL13G43K1euZMGCBXg8nnzLTj75ZDp16sSBAwdYvHhxWYR51CUnJ+N2u21/P0QAACAASURBVFm8eDFhYTpZlVJHk1b0y1ZDNjKV7rTmt3zpP9CBm5nEbmqHKDKllFJKKVVSRVb0H3roIQYNGkSdOnWK3EhsbCzDhw8nPj6+2G9sjGHBggV8+eWXBSr5jRo14t133+Wyyy4r9vYqgi1btnDqqafy4osv4nJViOkPlFLqsBqykc+5nrNY6UszwHza05skdlH0OUAppZRSSlUsRdZGx44dy7333nvYir5XcbvXG2NYtWoVDzzwAFu2bMm3LDExkbFjx3LJJZccE931gxGRYzZ2pdTxxNCAzUylO2exMt9c+tlE0ZcPtJKvlFJKKXUMKvdmZ2MM27dvp3///qxatSrfspiYGCIjI2nWrJl2fVdKqaPMW8kP7K4PYBAyiQlBVEoppZRS6kgVWdE/4YQTynxSuYMHDzJo0CAWLFiQb2b6E088kfvuu48RI0awefNmateumONBc3Nz2b17N6tWrWLt2rXk5OTQqFEj2rRpU2AIglJKVVTxHGQq3TmHZfnSM4lmN4nUYk+IIlNKKaWUUkeqyIr+jBkzOPnkk8vszXJycnjnnXeYPHkybrfblx4fH8+LL77IFVdcweTJk/n1119p06ZNmb1vWTDGsGPHDt59912SkpLYvHkzbreb8PBwYmNjadWqFVu3buW0004LdahKKVWkMNx0Zyot+D1fei4uBjGcL+nKclpxNTMZz50hilIppZRSSpVWkRX9li1bltkbGWP4/vvvGTVqFHl5eb70yMhIBg8eTM+ePcnLy+P0009n2bJlvkp0RWCMYcmSJTz00EMsWbIEt9tNWFgYZ599Nr1796ZLly4YY+jdu3eoQ1VKqcO6nfd5nf5EkutLyyGCAYzgTe7HQxjvczsd+J9W9JVSSimljkHlMkbfGMOWLVsYMmQI+/bt86WHh4dz22230a9fP6KiooiIiKB58+bMnTuXgwcPUrNm6J/ZbIzh999/5/bbb2f16tWAHdLw4IMPcvvtt3PSSScBsGzZMvbs2YPH48k3JEEppSqSBPbyIG8QQ1a+9Fd4hDE8gNs5LaRThTP4g6qkkkZcKEJVSimllFKlVCYVfWMMqamphc4073a7efvtt1m2LP9Y0HPPPZfHHnsMYwwpKSmAfbReUlISGzduBCAsLCyks9inpaXxzDPPsGbNGgDf4/Muv/xyXC4XKSkpZGZmMmLECLZu3YoxhrS0tArTG0Gpyqokj/NUXoZuTOOsgC77aziD97ndV8kHSKMql/M9zVjNItqWd6BKKaWUUuoIlElFPy0tjVtvvbXQZ8fn5uayZMmSfJPVhYeHk5mZyYMPPuhL83g8HDhwgM2bN3PbbbcRHR1NZGQk0dHRiAhhYWHlPht/WloaixcvxhhDZGQkVapUYezYsYwbN84X8+7du303Ar7++usCTxNQSpUtt9vNnDlzQh3GMSeGTJ7kxXxp62nMDXzGnzTxpYWTx++0IINY+vIBHfnOt+xjerKRRnjQm5lKHe/CyCMED3BSSilVDGVSOsfGxjJs2DCqVKlSYJnH42HcuHHMnz/flxYREcEzzzxD586dfWl//vknb731FsuWLcMY46s4e4WHh3P++edzzz33lOvj98aNG8fChQs544wzGDVqFHXqHHqm9K5duxg5ciSrVq3CGMNpp53GW2+9RfXq1cslNqWON7m5ufzwww+8/fbboQ7lmHQvb1OPrb7XBphCD9Zyhi+tFrt5n9u5iB+JI417eC/fNh5gDJO4mQn8i+WcXV6hK6UqmDOYT0feBiaHOhSllFJBlElFPzw8nLPOOotq1aoVWJaamsqWLVvytea3b9+ee++9l4SEBDweD4sWLWLEiBEsX7680PHtbrebhQsXsmvXLl5++WWuvfZaIiIiyiL8ItWrV4+YmBieffZZrrzySsLCwsjJyWHJkiWMHj2a+fPnY4whPj6eQYMG0aFDh5ANM1CqMsvKyuKtt95i9OjR7N27N9ThHHMiyKExG3Bx6Iknn3ATzzPY9zqBvfyX27iKWYVupza7eZRX6MEUbuITfqbdUY1bKVXRGC5gCnfTjyocQCv6SilVMR31/lYpKSn89ttvvtfR0dHcdddd1KxZE2MMmzZt4t5772XFihWH3ZYxho0bN3Lffffhcrno2rXrUW/Zv/DCC2nWrBnt2rUjMzOTv//+m/HjxzNx4kR2794N2LHCgwcPDjrrfk5ODnPmzGHHjh106tSJk046SW8EKFVCbrebpKQkhgwZQlpaWqjDOSbVZhe3877vdSpVeYv7yCIGgJrsI4ne+brpF6Ue2/iEm+jBFH7hAkDLNaUqO8HD+UyjH3cRQ2qow1FKKVWEYlf0/VvaS1JR3b59e76Z9uvVq8fll1+OiJCVlcXo0aP5/ff8E0OFh4cTFhZGkyZN8Hg8bNq0iaysQzNE79mzh0GDBtG8eXNOPfXUo1pxPv/887n++ut5+umn2bZtG4sXL+bAgQN4PB5cLhetW7dm4MCBdO7cmaioqHzrejweJk+ezEMPPURGRgYXX3wxn3/+OVWrVj1q8SpVGW3atIlhw4ZpJb8MZRDLMlo7rwxP8iId+c5XXTeAQRAMBsE4S8Lw+PLUYxufciPX8zlLOL+cP4FSqrzFs5t+3KmVfKWUOgYUqzncGMPq1asZM2aM7xFzxbV37958Nwn+7//+zzdb9pYtW5g2bZqvW39UVBQ9evRg0qRJnHLKKfTv35/vv/+e7777jj59+hAXd+gRT3/++Sdjx44lLy+vRPGUVGxsLP3796dr167UqlWL5s2b06FDB+644w4mT57MjBkzuO666wpU8gHy8vJYtGgRBw8eJDc3l19//TXfTQ+lVPFMnz6dbdu2hTqMSuU/PEYGsQA0YiN9+NBXgc8kmplcTVsWsoKWDOQlmrGaZqzmQ/rgP8DqJLZzJ+OIJLvcP4NSqnx1ZSSxpIQ6DKWUUsVQrBb9tLQ0Bg8ezBdffMHVV1/N9OnTC51hP1BGRka+in6rVq18j55btmwZu3btAuwEff3792fw4MFER0fz5ptv8vfff1O7dm1OPPFEzjnnHNq2bcugQYPYv38/Ho+HKVOm8Oijj1K7du2Sfu4SqVKlCl27dqVLly5kZWXhcrmIiIg4bE8Cl8vFxRdfzPTp00lNTeXyyy/nhBNOOKqxKlXZeDweVqxYgdvtPnxmVWx7qIVx7vXWYys12A9ABjEMYjhv8CCGMLKIJg8Xf9IEQxj9eZ2v6MJoHuUUtgBwM5N4mufYzdEti5VSoVWN3QjB51JSSilVsRSrth4WFkZ8fDzR0dFUr169RF3lq1at6svvcrlITEz0vd6wYYPvJkDbtm0ZMGCAr9W+VatWLF26lLy8PMLDw4mJieH222/nwIEDDBkyhOzsbLZv386yZcu46qqrSvShSyssLIzY2NgS5e/evTv169dnz549tGvXrkTrK6XsUKGYmJhQh1GpDWK47+J9EW14nf54x9xnE8W/Gck79COTWNKIYxrdqMUe3uR+wvEgGCLJCeEnUEoppZRS/orVdT82NpZRo0Yxffp0Ro8e7WuRL46TTz7Z1/ofHh6eryXcfyb+G2+8kYSEBEQEEeG8885jzZo1+cbkulwu7rrrLlq0aAHYCbrWrVtX7FhCITw8nAsuuICuXbv6Pp9SqvhEhC5duuhNsqPIOwLfAAtpi//EesMYEqQFT/iIW1nPaQDEkMkghpdXuEqpENnA+bgp/jWgUkqp0ClWi76IkJiYyBVXXBF0eV5eHr/88kvQC/H9+/dTvXp1du7cSW5uLitXriQxMRGwj97z38aPP/7oe52RkUF6ejqff/45TZo0ybfNpk2bsnTpUjweD7/++ivz588vzsdQSh2joqOjueSSS/jmm28KfQSnKloOkWylHqeyscCyUTzuTMRnmEyvfMvSqUIkOdRnC+s43ZeeSQwvMZAP6YsAVUg/2h9BKRVi39GPCLK4iad1Xg6llKrgyuTxepmZmbz66quFjtuPj49n586deDweJkyYwK+//oqIkJ2dTdWqVUlLS2PChAnMmTPHt05Oju0GOmrUKBo3bpxve/v27fO1jC9btowRI0aUxcdQqsLweDxH/dGRxxoRoXPnzmRmZpKRkRHqcI45u6nNRG5hCM8CUJ0DCB4MYWymAWlUJS7ITNobaMwqmtOHDxnES35LhG2cVE7RK6UqAjcRzOAxtnImUc7NvRtDHJNSSqngyqSiHxcXR1JSUr5Z8f3Nnj2bXr16kZqaSoMGDfj444+Jjo4mOzubRx55hPfff5/27dszYsQIXwU+KyuLW265hTp16hS4ibBgwQKuuuoqPB4PTz/9NDfccENZfAylQm7//v1MnTqVv/76i2bNmnHttdf6nlIB9gkYOvxDldaPXEQKccSTygBG8B53k0EVNtCYD+hLf17nKr7hd87yrZNMAn9zSpHbzSGC2XQ62uErpSqEMH7j6lAHoZRS6jDKpKIPh8bfB9OhQwfatWvHrFmzWL58OX/88Qfnn38+LpeLJ554gkWLFjFt2jS6devGRRddhIjgcrlo0aIFCxYsICsrixo1agC2onPgwAFycnKoVasWbdq0KfR9lTqWHDhwgP79+zN9+nSys7OJjo7mxx9/ZMyYMVSpUoWcnBymTJlCixYtaNmyZb51c3Nz8Xg8REZG6o0AVah5XMx82tOFmVQhneasYjFtAGE4gzib37iVj5jEzWyjXr51m7KOKqSRTtUC280lgu+5vJw+hVJKKaWUOpxy6RscExPDgAEDqFOnDgcPHuS9994jMzMTEaFRo0aMHTuWE088kQceeIA5c+bg8XgQEc455xzWr1/PwYMHfdsyxvi6+F9zzTXUrVu3PD6CUkfd4sWL+fzzz8nOtuMes7KymDJlCsuWLQNg9erVDBw40PdISrDHw9KlS+nWrRtXXXUVs2fPzjfJpVL+8ojgdfqTRhXiSeV+3iSKLAB2UYeb+IQ91OITbuJEtvnWe5P76ch3JLLbb2uG/rwOwAf0ZT81yvOjKKWUUkqpIpRLRV9EaN++PQ8//DARERF88sknfPvtt75xyOeffz6ffPIJN9xwA7///jt5eXkAtGzZkoyMDDZs2ADYSs26deuYOXMmJ554Ivfddx9RUVHl8RGUOuo2bdrkm5vCKzc3l507d7Jjxw6GDh1KdHS076kTYI+Jl19+ma+++or//e9/PPfccyQnJ5d36OoY8h0deZTRZBLNzUziDP7wLdtJXXoxmc+4gRv4zJe+mQZ4CKMqh56CEkMmTfiTjTRkLHeRS2S5fg6llFJKKVW4cpvtKzw8nHvvvZf77ruPrKwsnnjiCZYsWeIbc1y/fn0GDx7Mgw8+6OuKX7NmTRo3bszSpUsxxpCWlsYLL7zA3r17eeKJJ2jZsqV2U1aVxplnnkmVKlXypSUkJOB2u+nXrx9fffUVF154oW8Yi5f3xhjYir/OSq+KJoznDvrzOnm4+IC+NGQjOI/Q20ldXuVh3qFfvrXCcTOY5wGIJpN3uYfGbODfjGSl35h+pZRSSikVeuU6rXd8fDxDhgxh4MCB7N69m759+zJz5kxycnIQEcLDw3G5XL7Ku7f1ctmyZezYsYOBAwfy9ddf8/jjj3PHHXforOSqUjn33HMZPHgwderU8aWlpaXx1FNPkZmZSYMGDbj44ovz9WIREZ544gk6d+5Mhw4dePLJJ0lISAhF+OoY4iGc97mdBxjDaaxnKt25kllEYHuUGMLytdDv5QTe5H4iySGOFN7lHnqTxHju4FuuAPSGq1JKKaVURVJmk/EVV/Xq1Rk8eDBnn302L7/8Mv369eP666/njjvuoGHDhsTFxfkq8GFhYTRs2JBx48Zx0003sWfPHkaOHEnv3r2JiYkp79CVOqpiYmJ47LHHuPzyy1mwYAHbt2+nVq1anH/++Xg8Hvr16+ebrNJLRGjbti2ffPIJHo+HuLg47eWiisVDOOO4kzA8DGAEX9KVl3nCmYjvJFI59LQHNy6SqcmF/MwsrqQOO+nGNOZwWdDJ+ZRSSimlVGiVWUU/JyfHN4lYcVx99dW0adOG6dOn8+mnn3LNNdfQsmVLTj/9dBISEsjLy2Pbtm38/PPP7Nixg06dOvH222/TuHFjRKRE76XUsaRFixY0b97c91pEGDNmDCeddBJ169YN+tv3DncJHONfmen8HGVBeI+7mUp3epPEeSzhFy5gLpewhfq+XAahKes4gb1MoQfvcTe/0wJtyVdKKaWUqpjKpKKflpbGfffdV6rH3BljqF69Oo0aNWLt2rX88ssvvq78VapU8bVQrl+/nhdffLEswlXqmPPzzz8TGxvL3XffrS32jqSkpFCHUEkIySQwhgeJIouHeZVbmEgzVvtypBLHHYznZy7kc67ndx2Tr5RSSilVoZVJRT8qKooePXoQGxtbFpvLx+PxMHjwYGrUqMHNN99c5ttXqqLbuHEjixcv5u677+a0004LdTiqEssmmmyieYP+BZa5yMVNOKexnh+4FG3NV0oppZSquMqkoh8REUGnTp2oVq1aWWwuH4/Hw/fff8/69eu56qqrdAI+dVwxxpCUlERiYiK33XZbgRn3lSovbsL5gL7cz5u8yz2hDkcppZRSShWhwteaRYRzzjmHTZs2kZKSEupwlCpXeXl5/PDDD5x33nlUr1491OGo45ghzBmXr5RSSimlKroKX9EHaNSoEQCbNm0KcSRKla/U1FQWLFjAFVdcoWPzVYVQnQOcxvpQh6GUUkoppYoQkoq+MYaMjAzWrVvH8uXL2bRpE7m5uUHziggnnHACLpeLLVu2lHOkSoXW4sWLiY2N5cwzzwx1KKoSa8pazmcRDSj6Zup82rOL2lzGnHKKTCmllFJKlUa5V/SNMWzevJn777+fyy67jP/7v/+jU6dODB06lH379mGMKbBO1apVcblc2nVfHVfcbjdz587ljDPOoE6dOqEOR1VCVUllNI/wA5eykLZ8yxUMYShRZAXNv5+aHKTs52JRSimllFJlq0wm4yuJ5ORk7rrrLn744QdfpX7Dhg2MGDGC9PR0Ro0ahctVMCxjDB6Pp7zDVSpk0tPTWbNmDV26dNFnxqsyV5VUPqAv3ZhGGLYsbsJ6nuY5apLMI7yCh/AQR6mUUkoppUqj3Fv0p06dyvz58wu03Ofl5TFlyhTWry849jMlJYW8vLyjMqu/UhVVbGwsQ4cOpUePHjo+X5W5oQzNV8n3CsdDTz6mKesKrFOHHdRiT3mFqJRSSimlSqlcK/oej4dFixYVOh4/NTWVjRs35kvzdvXPysri1FNPLY8wlaoQXC4XrVu31tn21VFRk+QClXyvRPZwPZ8XSG/DIuJI5Su6HO3wlFJKKaXUESj3Fv1g3fK9IiMjqVmzZr60vLw8pk6dyimnnEKTJk2OdnhKKXXc20dNZtMpX1oYbrozlT3UYiv1QhSZUkoppZQqjnKt6IsIl19+eaHjjc8991zOOuss32u3281XX33F7Nmzueeee4iMjCyvUJVSqlL7mQvJLWSalm+4imW09ksxnMOvXMkshjGkfAJUSimllFKlVu4V/SuvvJJevXrla9mPjo7msssuY8SIEcTGxgKQmZnJZ599xmOPPcb1119P586ddZyyUkqVkU+5kT84I1+aAX6hLe/QL99EfG1ZyGfcwKfcyDwuBrQsVkoppZSqyMp91v34+HhGjBhBZGQkSUlJREVF0bdvX3r27EliYiL//PMP69atY8KECcybN49rrrmGIUOGULVq1fIOVSmlKq2DVKcb0+jOVJ7hWcLw8CzP8A1XkUI8jfgLgId5lWuYwTdcxeOMIoMqIY5cKaWUUkodjgR7br2fIhcCDBgwgPHjx7Nx48Ziz4pvjCErK4sZM2YwduxYli5dSlxcHPHx8aSkpJCWlkabNm2466676NKlCxEREdqar5QKdNwUCjLs8GVxqbeNhxv5lH68wzn8ShgeosgmkxgAdlKH1+nPWO4iB33Mo1IqPzPk+CiLj2Y5rJRSR6KwcrjcW/TBduGPiYmhe/fudOjQgS+++IJvv/2W9PR02rZtS/fu3alfvz5VqlQ5biv4xhgyMzPJy8vzpUVHR+s8BUqpMmUIYwo38TWdiSWDU/mLHkzhZZ7AQxi5RLCfmoffkFJKKaWUqjBCUtH3ysjI4Pnnn2fLli3cfPPNZGVlMWHCBOrVq0fTpk2P20o+2DkKHn30UX766SfAPq3giSeeoGfPniGOTClVGaURRxpx7KY2v3BhqMNRSimllFJHoNwfr+dv9+7dTJs2jd69e9O9e3d69+7NRRddxH//+18OHDgQytBKxBjDgQMH2LZtGykpKRxmOESxREZGctNNNzFo0CAAVq1axb59+454u0oppZRSSimlKreQVvSrV6/OOeecw6JFi9i3bx/bt2/n119/JSYmJt+s/MeCJ598klNPPZVXX30Vj8dzxNtzuVx06NCBnj17Urdu3TKIUCmllFJKKaXU8SCktenq1aszaNAgXn75ZR588EGys7M5cOAAzz77LPHx8aEMrcRyc3PJzs7ON6ZeKaWUUkoppZQqbyGt6G/ZsoXHHnuMbt260adPH/Ly8khKSmLz5s20adNGJ55TSimllFJKKaVKKKQV/QULFrBmzRqmTp1KzZo1McbQokUL+vXrxznnnMOZZ54ZdD2Px0NqamqB1vOoqCjfTP3eWeuzsrKIi4sjIiKi0HX918vLyyM9PZ3t27ezadMmsrOzOeGEE2jSpAk1a9b0bccrIyODjIwMsrOzATuJXnJyMmFhdlRETEwMsbGxvvzeuLZv38769evJysoiISGBU089lRo1ahATE1PkJIRut5vdu3ezYsUKcnJyaNy4MY0aNSIqKuq4nrxQKaWUUkoppZQV0oq+dyx74OR1+/btIy0tDWNM0Mrrnj176NGjB8uXL/etKyL06tWLV199lejoaHJzcxk8eDCTJk1i0qRJXHbZZYgIKSkp9O7dm59++sm3/b59+zJy5Ehyc3N55513mDRpEv/88w/16tUjOjqarVu3EhYWRt++fenfvz/Vq1f3xfXaa68xcuRI0tLSAHjjjTd47733fDENGDCAJ5980vd5ly1bxksvvcT8+fOpW7cucXFxbN++nbS0NC644AJuu+02unTpErQ3gzGGpKQknn32WbZt24YxhujoaG688UaGDx9OzZo1tbKvlFJKKaWUUse5kFb027ZtS2JiIpMmTeLOO+8kOzubqVOncvrpp3PiiScWWmmtUaMGr7zyCpMnT+bVV1+ladOmvPLKK9SvX99XQT548CBfffUVu3fv5ptvvuHSSy9FRKhatSrDhw9n3rx5DB8+nOeff5727dsTHh7O3r17+eijj3yP+WvRogUul4vk5GRGjx7NyJEj2bdvH6NGjfK9T+/evWnXrh0jR47kq6++omfPnvTp08fXol+/fn3AVtLnz5/PHXfcQXZ2NqNGjeKyyy4jIiKCAwcO8PbbbzNmzBhSUlLo0KFD0Ir+nDlzSE9P595776Vhw4asXLmSd955hw8//JBGjRrx73//m/Dw8KPxVSmllFJKKaWUOkaEtKJ/6qmnMm7cOJKSkhg4cCAej4eoqCjefPNNTjzxxELXi4yMpHXr1kRFRfHBBx+wf/9+X/d6782BhQsXsnXrVgBmz57NM888Q7Vq1XC5XLRo0YKZM2fSpEkTrr32Wk444QQAwsLCqFOnDj169KBjx46+ynpiYiLPP/88ixYtIikpiT59+tC6dWsATjnlFOrXr8+ECRMAW7G/6KKLClS4d+7cyVNPPcXmzZt56aWXuPnmm315EhMTeeqpp1i6dClutzvo4/ny8vJYuXIlkyZNok2bNogI1157LS6Xi8GDBzNz5kzuueceatSocSRfiVJKKaWUUkqpY1xIK/rh4eG0a9eOCy+8MF8XfO/f4TRu3JjWrVszZ84cFixYQMuWLRERcnNzmTlzJmeffTbr169ny5YtLFq0iI4dO/q673/33XdcdNFFJCQk+LaXkJDAu+++S0JCgm+cvzcu742EtWvXsnjxYl9Fv7gWLFjAwoULSUhI4Prrry9wI6BmzZr07NmTZcuWFdoqf9FFF9G6dWvfvgkLC6NDhw6Eh4ezefNmMjIytKKvlFJKKaWUUse5kD+svriV+mAiIiLo0qULc+bMYcaMGdxzzz1ERkaya9cuFi9ezL333svs2bOZOnUqc+bM4dJLL8XlcrFp0yZWrVrFSy+9lO+9XS4XJ598Mtu2bWPOnDls3bqVtLQ031wCGzZsIC8vj3379pU41nnz5uHxeGjUqBHVq1cvsDwsLIw777yTvLy8fJP3eYWHh9O0adMCkwFWrVqVKlWqkJ6ejtvtLnFcSimllFJKKaUql5BX9I9EWFgYF110EbVr1+a3337jzz//pHnz5qxcuZI9e/bQqVMnYmJi+Pzzz5k1axZPPPEENWrUYMaMGTRt2pQmTZrk215mZibvv/8+b7zxBsnJyb7J8rxd+L0T4JWmQr1lyxbAzi8QWFn3ioqKIioqKugyESEuLq7ATZGwsDBcLpfvZoRSSimllFJKqeNbWKgDOFLNmjWjWbNmHDhwgO+++w63280XX3xBu3btqFOnDueddx6nnHIKf/75JytWrGD//v3MnTuXjh07Eh8f79uOMYYvvviCgQMHsmfPHkaNGsX333/PvHnzmDdvHvPnz6dTp06ljtN/3H1pezDojPpKKaWUUkoppQ7nmK/oR0REcM0115CXl8d3333Hhg0bWLp0KZ07dyYyMpKGDRvSunVrcnJymDlzJuvWrWPTpk35JtsD++i7iRMnkpaWRpcuXejRowe1atUiPDy8TCrY3skFU1JSyM3NLbDcGIPH4yl0Mj6llFJKKaWUUqo4jvmKPsDFF19MrVq1+Pnnn/niiy/IysqiXbt2iAiRkZF07drV93i7pKQkEhMTadWqVYEKvHeW/pNPFY/fnAAADkZJREFUPhmXq+Cohuzs7EJjCHYzwFt5N8bQvn17RIRNmzZx8ODBAnk9Hg8zZ87k+eefZ8eOHSXdBUoppZRSSimlFFAJKvoiQsOGDTnnnHNISUnhlVdeoVmzZjRo0MCXp127dtStW5eVK1eSlJTENddcQ3R0dIFteZ95/8cff+Sr1Btj2LlzJ+vWrSs0Du8Eejk5Ob4W+ffee4+OHTuyY8cO2rdvT6tWrdi1axffffddgTH1e/fuZfjw4cyaNStfTwOllFJKKaWUUqokKkWNMi4uzvfovN27d3PdddflqyzXqVOH9u3bk52djYjQoUOHoJPa9erVi6pVq/Ltt9/yzjvvsHPnTg4ePMjmzZsZNmwYf//9NwB79uzhjz/+4ODBg75K/ZlnnomIsG7dOpKTk9mxYwdffPEFycnJREZGUq9ePZ577jkSExMZMWIEs2bN4uDBg6SlpbFt2zZefvll1qxZw4MPPkjt2rXxeDzs2LGDtWvXkp6eDsCuXbtYt24d6enpeDweNmzYwKZNm3C73bjdbjZs2MBff/2ls+8rpZRSSiml1HFMDjMe/LCDxQcMGMD48ePZuHEj1apVK7vISuiPP/6gXbt2JCQkMHPmTE477TRfZd4YwwcffMADDzxA69at+frrr/NNxOfNk52dzVtvvcV//vMf9u7dS926dUlISCAzM5Pu3buzYsUKZs6cicvlIiIignfffZdevXoBdlb9vn378vPPP9O6dWuysrLYtWsXI0aMoGfPnoSHh5OXl8fcuXN54YUXWLlyJU2bNiU+Pp6//vqLiIgIHn/8cW6++WaioqLIzs7m4YcfZuLEifx/e/caG0X1/3H8Mzvb7i5L2dbd0i6kRZPGS4AIGCOt0UbBaFJqvETkVmIEakwk1bQhhCaaf4xoakAMVSTeCGBp8JYi2EAIPCkFCiKgGDEkiqBioS1dW7q37vwfGDb21xZQe3N4v5I+6Jk5s2faZDKfne85E4lElEgklJKSorS0NNXW1qqgoEBTpkzRmTNnktUHbrdbeXl52rt3rzIyMob2HwAMvetmdUrj/65+LQaA4WC9dH1ci7kOAxip+rsO2ybox+NxnTlzRqZpaty4cb3m2Hd2durcuXPyeDwKBoP9LrAXi8V05swZHTt2TOfPn1dGRoZuv/12TZgwQW1tbfrjjz+S+2ZlZSVfeWdZlpqbm/XVV1/p7Nmz8nq9mjZtmvLy8nq8Ts+yLLW1tenUqVP6/vvvFYlElJOTo0mTJikYDMo0zeR+zc3NCoVCPcbncDgUDAbldrt1+vRpxePxHtsvVw9cPg5gY9fFzaXEDSaAkYugDwDDy/ZBH8B157q4uZS4wQQwchH0AWB49XcdtsUcfQAAAAAA8CeCPgAAAAAANkLQBwAAAADARgj6AAAAAADYCEEfAAAAAAAbIegDAAAAAGAjBH0AAAAAAGyEoA8AAAAAgI0Q9AEAAAAAsBGCPgAAAAAANkLQBwAAAADARgj6AAAAAADYCEEfAAAAAAAbIegDAAAAAGAjBH0AAAAAAGyEoA8AAAAAgI0Q9AEAAAAAsBGCPgAAAAAANkLQBwAAAADARgj6AAAAAADYCEEfAAAAAAAbIegDAAAAAGAjBH0AAAAAAGyEoA8AAAAAgI0Q9AEAAAAAsBGCPgAAAAAANkLQBwAAAADARgj6AAAAAADYCEEfAAAAAAAbcQ7EQRKJhH7//Xd1dnYOxOEA4KrGjRs33EMAAAAARqQBCfodHR2aO3euTNO8pv3j8bjC4bA6OjoUj8eVSCQkSZZlyTRNuVwueb1euVyuaz4m0N3drebmZkUikWvu4/F4lJmZKYeD4pb/mqampuEeAgAAADAiDUjQT0tL09atWzV69Ogr7pdIJHTs2DGtW7dOJ0+e1IwZM1RQUKCcnBxFo1GdOHFCO3fu1MGDB2WapmbOnKmSkhJNnz5dTueADBU21traqgULFujIkSPX3GfmzJlav369vF7vII4MAAAAAIbOgKRnwzAUCATk8/n63ScajaqmpkZVVVWaPn26tm7dqttuu01Op1OGYUiSiouLtWTJEm3evFkrV65UXV2dGhsbtXDhQpWXlys7Ozu5L/C/HA6HUlJS/laf1NRUZWZmKi0tbZBGBQAAAABDa0jqlbu7u1VTU6MVK1boscceU3V1tSZPnqyUlJQewd0wDPn9fi1dulSvvPKKPB6Pzp8/rzfeeEPPPPOMfvnlF1mWJenPMv9oNKqLFy8qGo0OxWkAAAAAADDiDXrQtyxL3333nV566SXl5+dr2bJlcrlcsiwrGdr/yjAMmaapefPm6fHHH5dhGEokEtqxY4fKy8uTC/5Fo1GtXbtWhYWFWrVqlbq7uwf7VJLnk0gk1NHRoZMnT+rbb79VS0uLEolEn+eDoWUYhhwOx9/6AQAAAAA7GfSJ77FYTB9++KF+++03ORwOFRUVKRQKKT8/X6WlpZo6dWqf5fher1fPPvusPv/8c3V2diqRSGjbtm3avHmzlixZolAopC1btuj48eMyDEOlpaXy+/2Dei7RaFSHDx9WTU2N9uzZo7a2NlmWJa/Xq1mzZun555/XjTfeyPSCYeLz+bRmzRq1t7dfc59AICCPxzOIowIAAACAoTXoQT8UCmn37t2KxWL65JNPku3Hjx9XQ0ODNm7c2G/YnzhxoqZMmaJ9+/ZJksLhsN5//3098sgjysjI0OzZs3Xp0iU98cQTV1wf4N+yLEutra1avXq13nvvPTU3N0uSxowZo6lTp6qoqEjp6elauXKlXn31VQUCgUEbC/qXmpqqu+66a7iHAQAAAADDatDrlru6uvTTTz/1ue3EiROqrq7ud479qFGjdOedd/Zo+/rrr3XixAmlpqaqoqJChw4d0vLlywdtVX7LstTe3q6ysjJVVVWpublZpmnq7rvv1saNG1VfX6+Kigo9+OCDOnr0qLZv304JPwAAAABg2AxoOu5vzv2Vgu+BAwcUDoeVmprae3BOp2666SaZppmcg9/d3a2DBw/q/vvvl2EYGjVqVL+fPRBisZjWrFmjjz/+WPF4XF6vV6WlpVq2bJnGjh2bPL/a2lodPXpUp06dUiKRYO43MMiYIgMAAAD0bUCCfjgc1ttvvy23291rW0dHhzwejzo6Ovrs29LS0m9fSWpqaurVVl9fP2Tzqtvb25NVBw6HQ3fccYcCgYC2bNmS3OfXX3/Vhg0bFI/HdeTIEb355puEEGCQvfDCC8M9BAAAAGBEGpCgf7m8PRwO97m9sLBQdXV1isViPdodDoemTZumrq6ufvtGo9FeoTkWi+nixYsDMfSramxsVEtLi9LS0jRnzhwFg0FFIhFFIhHFYjE1NDRo3759SiQS8vl8ysvL+1uLwQEAAAAAMJAGJOh7PB4tX75cY8aM6XN7KBSS1+tVbW2tIpGIJMk0TRUWFuqdd95RTk5Ov8fesGGDtm/f3qPtoYce0osvvthr38vl+//2abplWcljlJWVae/evSorK1NlZWVyikF7e7vWrVunb775JlmqX1JSolWrVsk0zX/1+QAAAAAA/FMDNkf/8vvL++Lz+bR27Vo98MAD2rVrl8LhsPLz8zV79mwFg8F+g/nl1e7/txLglltukcPhkGVZCofDcrlcMgxD+/fvVywW0z333POPwrZlWTp8+LBaW1s1c+ZMmaapWCwmv9+vxYsXy+12KxKJqKGhQatXr9bu3buTCwnOmjUruSjgX8/Hsiy1tLQoFAopNzd30BYNBAAAAABAGoLX60l/fgmQlpam+fPna86cOUokEr0CcV9isZh+/PHHHgvteb1eTZo0SbFYTOvXr9emTZs0d+5cLV26VIFAQOXl5Tpw4IBKSkoUDAavaVE8y7J04cIFffrpp9q2bZsqKyuT/caMGSOn06n9+/dr586d+uKLL9TY2KjW1lZJUnp6up588klVVlZq/PjxvY576NAhlZWV6cKFC5o/f75WrFjR58KDAAAAAAAMhCF/vGya5jU/be/q6tLx48d7tE2ePFnZ2dlqb2/Xpk2b1NTUpHA4rJKSEt1888167bXXVFFRoc8++0zFxcUqLi5Wbm6u3G63nE6nHA6HEomEuru7FYlEdO7cOdXX16uurk7RaFRVVVUqKChIfglhGIby8vK0Y8cO7dmzR52dnTIMQzk5Obr33nu1YMEC3XfffXK5XL3GH4/HVVNTowMHDkiS3nrrLS1atOiKUxUAAAAAAPg3RnQd+blz53oEfYfDoRkzZsjv9ysWi+nhhx9WW1ubiouL5fP5ZBiGJk6cqI8++kjvvvuuPvjgA73++uuaMGGCbr31Vo0dO1Yej0eRSEQXLlzQDz/8oFOnTsnn82n+/Pl67rnnNG7cuF6VBmPHjlV1dbUuXbqks2fPyuVyafz48cmn/f1VJjgcDmVmZsrpdCoejysQCAzZ2wIAAAAAANenERv0LcvSl19+qc7OzmRbenq6Hn30UTkcDrlcLpWXl2vRokXy+XzJue+GYcjv96uiokLz5s3Trl27tGvXLp0+fVrHjh1TOBxWamqq0tPTlZOTo4ULF6qoqEi5ublXLKlPSUlRMBhUMBi85nMwTVOlpaUKh8P6+eef9fTTT+uGG274538UAAAAAACuYsQG/dbWVtXV1am7uzvZVlxcrEmTJiV/d7vdys7O7rO/0+lUbm6uFi9erKeeeiq5IF40GlVKSopGjx6tQCAw6PPlMzMz9fLLLw/qZwAAAAAAcNmIDfqNjY3Jue2S5Pf7tWTJkn8UzJ1Op7KyspSVlTWQQwQAAAAAYMQx/rqiPQAAAAAA+G+7+rvnAAAAAADAfwZBHwAAAAAAGyHoAwAAAABgIwR9AAAAAABshKAPAAAAAICNEPQBAAAAALCR/weCs7RXNdakpwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1296x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_idx = 3\n",
    "\n",
    "print(f'image: {img_idx}')\n",
    "output_dir = 'output_test'\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(Image.open(os.path.join(output_dir, 'x{}.png'.format(img_idx))))\n",
    "plt.title('Input Image', fontsize=16)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(Image.open(os.path.join(output_dir, 'gt{}.png'.format(img_idx))))\n",
    "plt.title('Ground Truth Segmentation Map', fontsize=16)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(Image.open(os.path.join(output_dir, 'y{}.png'.format(img_idx))))\n",
    "plt.title('Predicted Segmentation Map', fontsize=16)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.gcf().set_size_inches(18, 10)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "part3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
